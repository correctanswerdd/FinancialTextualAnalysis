{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "text_matching.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ERFxdo2n4sO",
        "outputId": "d8cffe75-fccc-41de-df01-3cd891f49a1c"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = \"/content/drive/My Drive/Colab Notebooks/text3\"\n",
        "os.chdir(path)\n",
        "\n",
        "file_pattern = \"DS_Name.xlsx\"\n",
        "file_text = \"SPBank_AccurateName.xlsx\"\n",
        "remove = \"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+;\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BphBX6h1mhvF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "pattern = pd.read_excel(file_pattern)\n",
        "text = pd.read_excel(file_text)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iNsABrHmhvN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b2b73a8-32af-4eab-826c-32911caa44b9"
      },
      "source": [
        "import difflib\n",
        " \n",
        "def similarity3(s1, s2):\n",
        "    s1 = re.sub(remove, \" \", s1)\n",
        "    s2 = re.sub(remove, \" \", s2)\n",
        "    return difflib.SequenceMatcher(None, s1, s2).ratio()\n",
        "\n",
        "similarity1(\"Harris Bankcorp, Inc.\", \"ABN AMRO Asia\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36363636363636365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXuF7hJ_8UvZ",
        "outputId": "0d99f5cf-50da-4f86-9c46-88177c3dfe12"
      },
      "source": [
        "import difflib\n",
        " \n",
        "def similarity1(s1, s2):\n",
        "    s1 = re.sub(remove, \" \", s1)\n",
        "    s2 = re.sub(remove, \" \", s2)\n",
        "    return difflib.SequenceMatcher(None, s1, s2).quick_ratio()\n",
        "\n",
        "similarity1(\"Harris Bankcorp, Inc.\", \"ABN AMRO Asia\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.36363636363636365"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf066VUQ93fZ"
      },
      "source": [
        "# calculate the similarity of two company names - version 4\n",
        "from gensim import corpora, models, similarities\n",
        "import re\n",
        "\n",
        "n = len(text.axes[0])\n",
        "m = len(pattern.axes[0])\n",
        "\n",
        "wordList = []\n",
        "wordListCrsp = []\n",
        "\n",
        "for row in range(n):\n",
        "    txt = text['AccurateName'][row]\n",
        "    txt = re.sub(remove, \" \", txt)\n",
        "    segList = txt.lower().split()\n",
        "    wordList.append(segList) \n",
        "\n",
        "for row in range(m):\n",
        "    pat = pattern['lender'][row]\n",
        "    pat = re.sub(remove, \" \", pat)\n",
        "    segList = pat.lower().split()\n",
        "    wordListCrsp.append(segList)\n",
        "    wordList.append(segList)\n",
        "\n",
        "# 制作字典\n",
        "dictionary = corpora.Dictionary(wordList)\n",
        "# print(dictionary.token2id)\n",
        "\n",
        "\n",
        "# word to vec\n",
        "corpus = [dictionary.doc2bow(doc) for doc in wordList]\n",
        "corpusCrsp = [dictionary.doc2bow(doc) for doc in wordListCrsp]\n",
        "\n",
        "\n",
        "# 获取语料库每个文档中每个词的tfidf值，即用tfidf模型训练语料库\n",
        "tfidf = models.TfidfModel(corpus)\n",
        "\n",
        "#对稀疏向量建立索引\n",
        "index = similarities.SparseMatrixSimilarity(tfidf[corpusCrsp], num_features=len(dictionary.keys()))\n",
        "\n",
        "def similarity2(txt):\n",
        "    # 对测试文本分词\n",
        "    txt = re.sub(remove, \" \", txt)\n",
        "    dic_text_list = txt.lower().split()\n",
        "    \n",
        "    # 制作测试文本的词袋\n",
        "    doc_text_vec = dictionary.doc2bow(dic_text_list)\n",
        "\n",
        "    # 计算similarity\n",
        "    sim = index[tfidf[doc_text_vec]]    # 相当于sim = index.get_similarities(tfidf[doc_text_vec])\n",
        "\n",
        "    return sim"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbGI5KzsD5u1"
      },
      "source": [
        "# check sequence\n",
        "\n",
        "def if_sequence(txt, pat):\n",
        "    txt = re.sub(remove, \" \", txt)\n",
        "    txt_list = txt.lower().split()\n",
        "    txt_list_ = list(set(txt_list))\n",
        "    txt_list_.sort(key=txt_list.index)\n",
        "    d = dict(zip(txt_list_, range(len(txt_list))))\n",
        "\n",
        "    pat = re.sub(remove, \" \", pat)\n",
        "    pat_list = pat.lower().split()\n",
        "    i = 0\n",
        "    for p in pat_list:\n",
        "        if p in d and d[p] >= i:\n",
        "            i = d[p]\n",
        "        elif p in d and d[p] < i:\n",
        "            return True\n",
        "\n",
        "    return False"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "YgmhQKS0mhvO"
      },
      "source": [
        "import re\n",
        "\n",
        "n = len(text.axes[0])\n",
        "m = len(pattern.axes[0])\n",
        "count = 0\n",
        "output = []\n",
        "\n",
        "# match p to all companies in text1\n",
        "for row in range(n):\n",
        "    nid = text['AccurateName_id'][row]\n",
        "    txt = text['AccurateName'][row]\n",
        "\n",
        "    sim2 = similarity2(txt)\n",
        "\n",
        "    for row_ in range(m):\n",
        "        lcoid = pattern['lcoid'][row_]\n",
        "        pat = pattern['lender'][row_]\n",
        "\n",
        "        sim1 = similarity1(txt, pat)\n",
        "        sim3 = similarity3(txt, pat)\n",
        "\n",
        "        output_ = nid, txt, lcoid, pat, sim1, sim2[row_], sim3, int(if_sequence(txt, pat))\n",
        "        output.append(output_)\n",
        "\n",
        "        # if sim1 >= 0.95:\n",
        "        #     count += 1\n",
        "        #     output_ = nid, txt, lcoid, pat, sim1, sim2[row_], int(if_sequence(txt, pat))\n",
        "        #     output.append(output_)\n",
        "        # elif sim1 >= 0.8 and sim2[row_] > 0.5:\n",
        "        #     count += 1\n",
        "        #     output_ = nid, txt, lcoid, pat, sim1, sim2[row_], int(if_sequence(txt, pat))\n",
        "        #     output.append(output_)\n",
        "    # print(count)\n",
        "\n",
        "df = pd.DataFrame(output, columns=['AccurateName_id', 'AccurateName', 'lcoid', 'lender', 'sim1=quick_ratio', 'sim2=tfidf', 'sim3=ratio', 'dummy'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E_MoNkvmhvP"
      },
      "source": [
        "df[1000000:].to_excel('output2.xlsx', index = None, header=True)"
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}